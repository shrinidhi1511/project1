{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMulMPoKmMHnfpomkEd6Lrl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shrinidhi1511/project1/blob/main/foodprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiqRyY8ioCfG",
        "outputId": "6d1a6319-0a50-4419-d790-1ee654adf769"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-18 07:22:12.763 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.764 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.766 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.767 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.768 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.769 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.772 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.774 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.777 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.778 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.778 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.779 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.780 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.781 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.786 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.787 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.787 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.788 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.789 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.789 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.790 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.791 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.791 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.792 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.793 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.793 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.794 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.795 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.797 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.798 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 07:22:12.798 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "# app.py\n",
        "\"\"\"\n",
        "Digital Twin Hackathon Demo App\n",
        "Features:\n",
        " - Simple login (operator / manager)\n",
        " - Live simulated sensor stream (start / stop)\n",
        " - Virtual control panel (setpoints affect simulated values)\n",
        " - Upload CSV / JSON to feed dashboard instead of simulation\n",
        " - Role-based UI: operator vs manager\n",
        " - Downloadable batch reports (manager)\n",
        "\"\"\"\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from io import StringIO\n",
        "\n",
        "# -------------------------\n",
        "# --------- CONFIG --------\n",
        "# -------------------------\n",
        "USERS = {\n",
        "    \"operator\": {\"password\": \"op123\", \"role\": \"operator\"},\n",
        "    \"manager\": {\"password\": \"mg123\", \"role\": \"manager\"}\n",
        "}\n",
        "\n",
        "SIM_BATCH_SIZE = 20  # number of records per batch (batch_id increments every SIM_BATCH_SIZE rows)\n",
        "\n",
        "# -------------------------\n",
        "# ---- Helper functions ---\n",
        "# -------------------------\n",
        "def authenticate(username: str, password: str):\n",
        "    user = USERS.get(username)\n",
        "    if user and user[\"password\"] == password:\n",
        "        return {\"username\": username, \"role\": user[\"role\"]}\n",
        "    return None\n",
        "\n",
        "def init_session():\n",
        "    if \"logged_in\" not in st.session_state:\n",
        "        st.session_state.logged_in = False\n",
        "        st.session_state.user = None\n",
        "    if \"data\" not in st.session_state:\n",
        "        st.session_state.data = pd.DataFrame(columns=[\"timestamp\",\"temp\",\"humidity\",\"vibration\",\"batch_id\"])\n",
        "    if \"running\" not in st.session_state:\n",
        "        st.session_state.running = False\n",
        "    if \"sim_index\" not in st.session_state:\n",
        "        st.session_state.sim_index = 0\n",
        "    if \"setpoint_temp\" not in st.session_state:\n",
        "        st.session_state.setpoint_temp = 60.0\n",
        "        st.session_state.setpoint_humidity = 50.0\n",
        "        st.session_state.setpoint_vibration = 0.5\n",
        "\n",
        "def generate_record(i, setpoints):\n",
        "    \"\"\"Simulate one sensor record influenced by setpoints.\"\"\"\n",
        "    base_temp = setpoints[\"temp\"]\n",
        "    base_hum = setpoints[\"humidity\"]\n",
        "    base_vib = setpoints[\"vibration\"]\n",
        "\n",
        "    # add small random fluctuations, and occasional drift\n",
        "    temp = np.random.normal(base_temp, 2.0) + 0.5 * np.sin(i/10)\n",
        "    humidity = np.random.normal(base_hum, 1.5) + 0.2 * np.cos(i/13)\n",
        "    vibration = max(0.01, np.random.normal(base_vib, 0.05) + 0.02 * np.sin(i/7))\n",
        "\n",
        "    batch_id = f\"batch_{(i // SIM_BATCH_SIZE) + 1}\"\n",
        "    return {\n",
        "        \"timestamp\": pd.Timestamp.now(),\n",
        "        \"temp\": round(float(temp), 2),\n",
        "        \"humidity\": round(float(humidity), 2),\n",
        "        \"vibration\": round(float(vibration), 3),\n",
        "        \"batch_id\": batch_id\n",
        "    }\n",
        "\n",
        "def append_record(rec):\n",
        "    df = st.session_state.data\n",
        "    df = pd.concat([df, pd.DataFrame([rec])], ignore_index=True)\n",
        "    st.session_state.data = df\n",
        "\n",
        "def load_uploaded_file(uploaded_file):\n",
        "    try:\n",
        "        file_ext = uploaded_file.name.split(\".\")[-1].lower()\n",
        "        if file_ext in (\"csv\", \"txt\"):\n",
        "            df = pd.read_csv(uploaded_file)\n",
        "        elif file_ext in (\"json\",):\n",
        "            df = pd.read_json(uploaded_file)\n",
        "        else:\n",
        "            st.error(\"Unsupported file type. Please upload CSV or JSON.\")\n",
        "            return None\n",
        "\n",
        "        # Expect at least columns: timestamp,temp,humidity,vibration,batch_id\n",
        "        # If timestamp missing, create one.\n",
        "        if \"timestamp\" not in df.columns:\n",
        "            df[\"timestamp\"] = pd.Timestamp.now()\n",
        "        required = [\"timestamp\",\"temp\",\"humidity\",\"vibration\"]\n",
        "        for c in required:\n",
        "            if c not in df.columns:\n",
        "                st.error(f\"Uploaded file missing required column: {c}\")\n",
        "                return None\n",
        "\n",
        "        # Normalize columns and types\n",
        "        df = df[[\"timestamp\",\"temp\",\"humidity\",\"vibration\"]].copy()\n",
        "        if \"batch_id\" in uploaded_file.name:  # optional way to specify batches via filename\n",
        "            df[\"batch_id\"] = uploaded_file.name.split(\".\")[0]\n",
        "        else:\n",
        "            # create batch ids if not present\n",
        "            df[\"batch_id\"] = [f\"batch_{(i // SIM_BATCH_SIZE) + 1}\" for i in range(len(df))]\n",
        "\n",
        "        # coerce timestamp\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to parse uploaded file: {e}\")\n",
        "        return None\n",
        "\n",
        "# -------------------------\n",
        "# ------- UI LAYOUT -------\n",
        "# -------------------------\n",
        "st.set_page_config(page_title=\"Digital Twin Dashboard\", layout=\"wide\")\n",
        "init_session()\n",
        "\n",
        "if not st.session_state.logged_in:\n",
        "    st.title(\"🔐 Login\")\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        username = st.text_input(\"Username\")\n",
        "    with col2:\n",
        "        password = st.text_input(\"Password\", type=\"password\")\n",
        "\n",
        "    if st.button(\"Login\"):\n",
        "        auth = authenticate(username, password)\n",
        "        if auth:\n",
        "            st.session_state.logged_in = True\n",
        "            st.session_state.user = auth\n",
        "            st.experimental_rerun()\n",
        "        else:\n",
        "            st.error(\"Invalid username or password. Try 'operator/op123' or 'manager/mg123'.\")\n",
        "\n",
        "else:\n",
        "    user = st.session_state.user\n",
        "    st.sidebar.title(f\"Welcome, {user['username']} ({user['role']})\")\n",
        "    if st.sidebar.button(\"Logout\"):\n",
        "        # clear session and rerun\n",
        "        for k in list(st.session_state.keys()):\n",
        "            del st.session_state[k]\n",
        "        st.experimental_rerun()\n",
        "\n",
        "    # Navigation\n",
        "    page = st.sidebar.radio(\"Page\", [\"Dashboard\", \"Control Panel\", \"Upload Data\", \"Admin\" if user[\"role\"]==\"manager\" else \"Info\"])\n",
        "\n",
        "    # Top-level summary\n",
        "    st.markdown(\"## 🍪 Digital Twin — Food Process Demo\")\n",
        "    st.markdown(\"**Live mode:** Simulated data. You can upload real CSV/JSON to switch to offline mode.\")\n",
        "\n",
        "    # Right-side container for charts & table\n",
        "    if page == \"Dashboard\":\n",
        "        left, right = st.columns([3,1])\n",
        "\n",
        "        # Controls for simulation\n",
        "        with right:\n",
        "            st.subheader(\"Simulation Controls\")\n",
        "            if not st.session_state.running:\n",
        "                if st.button(\"Start Simulation\"):\n",
        "                    st.session_state.running = True\n",
        "            else:\n",
        "                if st.button(\"Stop Simulation\"):\n",
        "                    st.session_state.running = False\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "            st.write(\"Setpoints (affect simulation)\")\n",
        "            st.session_state.setpoint_temp = st.slider(\"Target Temp (°C)\", 20.0, 120.0, st.session_state.setpoint_temp)\n",
        "            st.session_state.setpoint_humidity = st.slider(\"Target Humidity (%)\", 0.0, 100.0, st.session_state.setpoint_humidity)\n",
        "            st.session_state.setpoint_vibration = st.slider(\"Target Vibration (g)\", 0.0, 5.0, st.session_state.setpoint_vibration)\n",
        "            st.markdown(\"---\")\n",
        "            st.write(\"Data source:\")\n",
        "            st.write(\"• If you've uploaded data, the app will display that. Otherwise the simulation runs.\")\n",
        "            if st.button(\"Clear Stored Data\"):\n",
        "                st.session_state.data = pd.DataFrame(columns=[\"timestamp\",\"temp\",\"humidity\",\"vibration\",\"batch_id\"])\n",
        "                st.success(\"Cleared stored data\")\n",
        "\n",
        "        # Main charts\n",
        "        with left:\n",
        "            st.subheader(\"Live Sensor Chart\")\n",
        "            chart_placeholder = st.empty()\n",
        "\n",
        "            st.subheader(\"Latest readings\")\n",
        "            data_table = st.empty()\n",
        "\n",
        "            # Insert uploaded data if present in session_state (upload page will fill it)\n",
        "            df = st.session_state.data.copy()\n",
        "\n",
        "            # If simulation running, generate a new record per rerun\n",
        "            if st.session_state.running:\n",
        "                # generate a single record per rerun (Streamlit reruns the script frequently)\n",
        "                rec = generate_record(st.session_state.sim_index, {\n",
        "                    \"temp\": st.session_state.setpoint_temp,\n",
        "                    \"humidity\": st.session_state.setpoint_humidity,\n",
        "                    \"vibration\": st.session_state.setpoint_vibration\n",
        "                })\n",
        "                append_record(rec)\n",
        "                st.session_state.sim_index += 1\n",
        "                # tiny pause so UI updates look natural (non-blocking enough)\n",
        "                time.sleep(0.25)\n",
        "\n",
        "            if df.empty:\n",
        "                st.info(\"No data yet. Start simulation or upload a file.\")\n",
        "            else:\n",
        "                # ensure timestamp is datetime and sorted\n",
        "                df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "                df = df.sort_values(\"timestamp\")\n",
        "                df2 = df.set_index(\"timestamp\")[[\"temp\",\"humidity\",\"vibration\"]].tail(300)\n",
        "\n",
        "                # show line chart\n",
        "                chart_placeholder.line_chart(df2)\n",
        "\n",
        "                # Latest table\n",
        "                data_table.dataframe(df.tail(10).reset_index(drop=True))\n",
        "\n",
        "            # Batch status: show last value per batch\n",
        "            st.subheader(\"Batch Status\")\n",
        "            if not df.empty:\n",
        "                last_per_batch = df.sort_values(\"timestamp\").groupby(\"batch_id\").tail(1)\n",
        "                st.table(last_per_batch[[\"batch_id\",\"temp\",\"humidity\",\"vibration\"]].reset_index(drop=True))\n",
        "\n",
        "    elif page == \"Control Panel\":\n",
        "        st.subheader(\"Virtual Control Panel\")\n",
        "        st.write(\"This panel simulates remote adjustments to the physical process. Changes affect subsequent simulated data.\")\n",
        "        st.markdown(\"- Adjust setpoints and then Start Simulation to observe the effect in the Dashboard.\")\n",
        "        st.write(\"Current setpoints:\")\n",
        "        st.write(f\"Temperature: {st.session_state.setpoint_temp} °C\")\n",
        "        st.write(f\"Humidity: {st.session_state.setpoint_humidity} %\")\n",
        "        st.write(f\"Vibration: {st.session_state.setpoint_vibration} g\")\n",
        "\n",
        "        if user[\"role\"] != \"operator\":\n",
        "            st.info(\"Control access is normally for operators. Managers can view and adjust for testing here.\")\n",
        "\n",
        "        # quick single-step controls (for demos)\n",
        "        if st.button(\"Simulate Heat Spike (+10°C) for 10 records\"):\n",
        "            base_t = st.session_state.setpoint_temp\n",
        "            for j in range(10):\n",
        "                rec = generate_record(st.session_state.sim_index + j, {\n",
        "                    \"temp\": base_t + 10,\n",
        "                    \"humidity\": st.session_state.setpoint_humidity,\n",
        "                    \"vibration\": st.session_state.setpoint_vibration\n",
        "                })\n",
        "                append_record(rec)\n",
        "            st.session_state.sim_index += 10\n",
        "            st.success(\"Injected heat spike (10 records)\")\n",
        "\n",
        "    elif page == \"Upload Data\":\n",
        "        st.subheader(\"Upload CSV or JSON sensor data\")\n",
        "        st.markdown(\"Expected columns: timestamp, temp, humidity, vibration (optional: batch_id). If timestamp absent, it will be added.\")\n",
        "        uploaded_file = st.file_uploader(\"Upload file\", type=[\"csv\",\"json\"])\n",
        "        if uploaded_file is not None:\n",
        "            df_uploaded = load_uploaded_file(uploaded_file)\n",
        "            if df_uploaded is not None:\n",
        "                st.session_state.data = pd.concat([st.session_state.data, df_uploaded], ignore_index=True)\n",
        "                st.success(f\"Loaded {len(df_uploaded)} rows from upload into session storage.\")\n",
        "                st.experimental_rerun()\n",
        "\n",
        "    elif page == \"Admin\":\n",
        "        st.subheader(\"Manager Analytics & Export\")\n",
        "        df = st.session_state.data.copy()\n",
        "        if df.empty:\n",
        "            st.info(\"No data to analyze. Start simulation or upload a file.\")\n",
        "        else:\n",
        "            df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "            st.markdown(\"**Summary statistics (latest data)**\")\n",
        "            st.write(df[[\"temp\",\"humidity\",\"vibration\"]].describe())\n",
        "\n",
        "            # simple anomaly rule: temp > setpoint + 10 or vibration > 1.5\n",
        "            df[\"anomaly_rule\"] = ((df[\"temp\"] > (st.session_state.setpoint_temp + 10)) | (df[\"vibration\"] > 1.5)).astype(int)\n",
        "            st.markdown(\"Anomaly counts by batch (rule-based)\")\n",
        "            anom_counts = df.groupby(\"batch_id\")[\"anomaly_rule\"].sum().reset_index().rename(columns={\"anomaly_rule\":\"anomaly_count\"})\n",
        "            st.table(anom_counts)\n",
        "\n",
        "            st.markdown(\"Download combined data (CSV)\")\n",
        "            csv = df.to_csv(index=False)\n",
        "            st.download_button(\"Download CSV\", data=csv, file_name=\"sensor_data_export.csv\", mime=\"text/csv\")\n",
        "\n",
        "    else:\n",
        "        st.subheader(\"Info\")\n",
        "        st.markdown(\"This demo app simulates a digital twin pipeline. Use the Upload page to test with real data. Use Control Panel to inject conditions and Dashboard to view live charts.\")\n",
        "\n",
        "    # footer: small help\n",
        "    st.markdown(\"---\")\n",
        "    st.caption(\"Demo app: operator credentials — user: operator / pass: op123. manager — user: manager / pass: mg123\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\"\"\"\n",
        "Digital Twin Hackathon Demo App\n",
        "Features:\n",
        " - Simple login (operator / manager)\n",
        " - Live simulated sensor stream (start / stop)\n",
        " - Virtual control panel (setpoints affect simulated values)\n",
        " - Upload CSV / JSON to feed dashboard instead of simulation\n",
        " - Role-based UI: operator vs manager\n",
        " - Downloadable batch reports (manager)\n",
        "\"\"\"\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from io import StringIO\n",
        "\n",
        "# -------------------------\n",
        "# --------- CONFIG --------\n",
        "# -------------------------\n",
        "USERS = {\n",
        "    \"operator\": {\"password\": \"op123\", \"role\": \"operator\"},\n",
        "    \"manager\": {\"password\": \"mg123\", \"role\": \"manager\"}\n",
        "}\n",
        "\n",
        "SIM_BATCH_SIZE = 20  # number of records per batch (batch_id increments every SIM_BATCH_SIZE rows)\n",
        "\n",
        "# -------------------------\n",
        "# ---- Helper functions ---\n",
        "# -------------------------\n",
        "def authenticate(username: str, password: str):\n",
        "    user = USERS.get(username)\n",
        "    if user and user[\"password\"] == password:\n",
        "        return {\"username\": username, \"role\": user[\"role\"]}\n",
        "    return None\n",
        "\n",
        "def init_session():\n",
        "    if \"logged_in\" not in st.session_state:\n",
        "        st.session_state.logged_in = False\n",
        "        st.session_state.user = None\n",
        "    if \"data\" not in st.session_state:\n",
        "        st.session_state.data = pd.DataFrame(columns=[\"timestamp\",\"temp\",\"humidity\",\"vibration\",\"batch_id\"])\n",
        "    if \"running\" not in st.session_state:\n",
        "        st.session_state.running = False\n",
        "    if \"sim_index\" not in st.session_state:\n",
        "        st.session_state.sim_index = 0\n",
        "    if \"setpoint_temp\" not in st.session_state:\n",
        "        st.session_state.setpoint_temp = 60.0\n",
        "        st.session_state.setpoint_humidity = 50.0\n",
        "        st.session_state.setpoint_vibration = 0.5\n",
        "\n",
        "def generate_record(i, setpoints):\n",
        "    \"\"\"Simulate one sensor record influenced by setpoints.\"\"\"\n",
        "    base_temp = setpoints[\"temp\"]\n",
        "    base_hum = setpoints[\"humidity\"]\n",
        "    base_vib = setpoints[\"vibration\"]\n",
        "\n",
        "    # add small random fluctuations, and occasional drift\n",
        "    temp = np.random.normal(base_temp, 2.0) + 0.5 * np.sin(i/10)\n",
        "    humidity = np.random.normal(base_hum, 1.5) + 0.2 * np.cos(i/13)\n",
        "    vibration = max(0.01, np.random.normal(base_vib, 0.05) + 0.02 * np.sin(i/7))\n",
        "\n",
        "    batch_id = f\"batch_{(i // SIM_BATCH_SIZE) + 1}\"\n",
        "    return {\n",
        "        \"timestamp\": pd.Timestamp.now(),\n",
        "        \"temp\": round(float(temp), 2),\n",
        "        \"humidity\": round(float(humidity), 2),\n",
        "        \"vibration\": round(float(vibration), 3),\n",
        "        \"batch_id\": batch_id\n",
        "    }\n",
        "\n",
        "def append_record(rec):\n",
        "    df = st.session_state.data\n",
        "    df = pd.concat([df, pd.DataFrame([rec])], ignore_index=True)\n",
        "    st.session_state.data = df\n",
        "\n",
        "def load_uploaded_file(uploaded_file):\n",
        "    try:\n",
        "        file_ext = uploaded_file.name.split(\".\")[-1].lower()\n",
        "        if file_ext in (\"csv\", \"txt\"):\n",
        "            df = pd.read_csv(uploaded_file)\n",
        "        elif file_ext in (\"json\",):\n",
        "            df = pd.read_json(uploaded_file)\n",
        "        else:\n",
        "            st.error(\"Unsupported file type. Please upload CSV or JSON.\")\n",
        "            return None\n",
        "\n",
        "        # Expect at least columns: timestamp,temp,humidity,vibration,batch_id\n",
        "        # If timestamp missing, create one.\n",
        "        if \"timestamp\" not in df.columns:\n",
        "            df[\"timestamp\"] = pd.Timestamp.now()\n",
        "        required = [\"timestamp\",\"temp\",\"humidity\",\"vibration\"]\n",
        "        for c in required:\n",
        "            if c not in df.columns:\n",
        "                st.error(f\"Uploaded file missing required column: {c}\")\n",
        "                return None\n",
        "\n",
        "        # Normalize columns and types\n",
        "        df = df[[\"timestamp\",\"temp\",\"humidity\",\"vibration\"]].copy()\n",
        "        if \"batch_id\" in uploaded_file.name:  # optional way to specify batches via filename\n",
        "            df[\"batch_id\"] = uploaded_file.name.split(\".\")[0]\n",
        "        else:\n",
        "            # create batch ids if not present\n",
        "            df[\"batch_id\"] = [f\"batch_{(i // SIM_BATCH_SIZE) + 1}\" for i in range(len(df))]\n",
        "\n",
        "        # coerce timestamp\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to parse uploaded file: {e}\")\n",
        "        return None\n",
        "\n",
        "# -------------------------\n",
        "# ------- UI LAYOUT -------\n",
        "# -------------------------\n",
        "st.set_page_config(page_title=\"Digital Twin Dashboard\", layout=\"wide\")\n",
        "init_session()\n",
        "\n",
        "if not st.session_state.logged_in:\n",
        "    st.title(\"🔐 Login\")\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        username = st.text_input(\"Username\")\n",
        "    with col2:\n",
        "        password = st.text_input(\"Password\", type=\"password\")\n",
        "\n",
        "    if st.button(\"Login\"):\n",
        "        auth = authenticate(username, password)\n",
        "        if auth:\n",
        "            st.session_state.logged_in = True\n",
        "            st.session_state.user = auth\n",
        "            st.experimental_rerun()\n",
        "        else:\n",
        "            st.error(\"Invalid username or password. Try 'operator/op123' or 'manager/mg123'.\")\n",
        "\n",
        "else:\n",
        "    user = st.session_state.user\n",
        "    st.sidebar.title(f\"Welcome, {user['username']} ({user['role']})\")\n",
        "    if st.sidebar.button(\"Logout\"):\n",
        "        # clear session and rerun\n",
        "        for k in list(st.session_state.keys()):\n",
        "            del st.session_state[k]\n",
        "        st.experimental_rerun()\n",
        "\n",
        "    # Navigation\n",
        "    page = st.sidebar.radio(\"Page\", [\"Dashboard\", \"Control Panel\", \"Upload Data\", \"Admin\" if user[\"role\"]==\"manager\" else \"Info\"])\n",
        "\n",
        "    # Top-level summary\n",
        "    st.markdown(\"## 🍪 Digital Twin — Food Process Demo\")\n",
        "    st.markdown(\"**Live mode:** Simulated data. You can upload real CSV/JSON to switch to offline mode.\")\n",
        "\n",
        "    # Right-side container for charts & table\n",
        "    if page == \"Dashboard\":\n",
        "        left, right = st.columns([3,1])\n",
        "\n",
        "        # Controls for simulation\n",
        "        with right:\n",
        "            st.subheader(\"Simulation Controls\")\n",
        "            if not st.session_state.running:\n",
        "                if st.button(\"Start Simulation\"):\n",
        "                    st.session_state.running = True\n",
        "            else:\n",
        "                if st.button(\"Stop Simulation\"):\n",
        "                    st.session_state.running = False\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "            st.write(\"Setpoints (affect simulation)\")\n",
        "            st.session_state.setpoint_temp = st.slider(\"Target Temp (°C)\", 20.0, 120.0, st.session_state.setpoint_temp)\n",
        "            st.session_state.setpoint_humidity = st.slider(\"Target Humidity (%)\", 0.0, 100.0, st.session_state.setpoint_humidity)\n",
        "            st.session_state.setpoint_vibration = st.slider(\"Target Vibration (g)\", 0.0, 5.0, st.session_state.setpoint_vibration)\n",
        "            st.markdown(\"---\")\n",
        "            st.write(\"Data source:\")\n",
        "            st.write(\"• If you've uploaded data, the app will display that. Otherwise the simulation runs.\")\n",
        "            if st.button(\"Clear Stored Data\"):\n",
        "                st.session_state.data = pd.DataFrame(columns=[\"timestamp\",\"temp\",\"humidity\",\"vibration\",\"batch_id\"])\n",
        "                st.success(\"Cleared stored data\")\n",
        "\n",
        "        # Main charts\n",
        "        with left:\n",
        "            st.subheader(\"Live Sensor Chart\")\n",
        "            chart_placeholder = st.empty()\n",
        "\n",
        "            st.subheader(\"Latest readings\")\n",
        "            data_table = st.empty()\n",
        "\n",
        "            # Insert uploaded data if present in session_state (upload page will fill it)\n",
        "            df = st.session_state.data.copy()\n",
        "\n",
        "            # If simulation running, generate a new record per rerun\n",
        "            if st.session_state.running:\n",
        "                # generate a single record per rerun (Streamlit reruns the script frequently)\n",
        "                rec = generate_record(st.session_state.sim_index, {\n",
        "                    \"temp\": st.session_state.setpoint_temp,\n",
        "                    \"humidity\": st.session_state.setpoint_humidity,\n",
        "                    \"vibration\": st.session_state.setpoint_vibration\n",
        "                })\n",
        "                append_record(rec)\n",
        "                st.session_state.sim_index += 1\n",
        "                # tiny pause so UI updates look natural (non-blocking enough)\n",
        "                time.sleep(0.25)\n",
        "\n",
        "            if df.empty:\n",
        "                st.info(\"No data yet. Start simulation or upload a file.\")\n",
        "            else:\n",
        "                # ensure timestamp is datetime and sorted\n",
        "                df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "                df = df.sort_values(\"timestamp\")\n",
        "                df2 = df.set_index(\"timestamp\")[[\"temp\",\"humidity\",\"vibration\"]].tail(300)\n",
        "\n",
        "                # show line chart\n",
        "                chart_placeholder.line_chart(df2)\n",
        "\n",
        "                # Latest table\n",
        "                data_table.dataframe(df.tail(10).reset_index(drop=True))\n",
        "\n",
        "            # Batch status: show last value per batch\n",
        "            st.subheader(\"Batch Status\")\n",
        "            if not df.empty:\n",
        "                last_per_batch = df.sort_values(\"timestamp\").groupby(\"batch_id\").tail(1)\n",
        "                st.table(last_per_batch[[\"batch_id\",\"temp\",\"humidity\",\"vibration\"]].reset_index(drop=True))\n",
        "\n",
        "    elif page == \"Control Panel\":\n",
        "        st.subheader(\"Virtual Control Panel\")\n",
        "        st.write(\"This panel simulates remote adjustments to the physical process. Changes affect subsequent simulated data.\")\n",
        "        st.markdown(\"- Adjust setpoints and then Start Simulation to observe the effect in the Dashboard.\")\n",
        "        st.write(\"Current setpoints:\")\n",
        "        st.write(f\"Temperature: {st.session_state.setpoint_temp} °C\")\n",
        "        st.write(f\"Humidity: {st.session_state.setpoint_humidity} %\")\n",
        "        st.write(f\"Vibration: {st.session_state.setpoint_vibration} g\")\n",
        "\n",
        "        if user[\"role\"] != \"operator\":\n",
        "            st.info(\"Control access is normally for operators. Managers can view and adjust for testing here.\")\n",
        "\n",
        "        # quick single-step controls (for demos)\n",
        "        if st.button(\"Simulate Heat Spike (+10°C) for 10 records\"):\n",
        "            base_t = st.session_state.setpoint_temp\n",
        "            for j in range(10):\n",
        "                rec = generate_record(st.session_state.sim_index + j, {\n",
        "                    \"temp\": base_t + 10,\n",
        "                    \"humidity\": st.session_state.setpoint_humidity,\n",
        "                    \"vibration\": st.session_state.setpoint_vibration\n",
        "                })\n",
        "                append_record(rec)\n",
        "            st.session_state.sim_index += 10\n",
        "            st.success(\"Injected heat spike (10 records)\")\n",
        "\n",
        "    elif page == \"Upload Data\":\n",
        "        st.subheader(\"Upload CSV or JSON sensor data\")\n",
        "        st.markdown(\"Expected columns: timestamp, temp, humidity, vibration (optional: batch_id). If timestamp absent, it will be added.\")\n",
        "        uploaded_file = st.file_uploader(\"Upload file\", type=[\"csv\",\"json\"])\n",
        "        if uploaded_file is not None:\n",
        "            df_uploaded = load_uploaded_file(uploaded_file)\n",
        "            if df_uploaded is not None:\n",
        "                st.session_state.data = pd.concat([st.session_state.data, df_uploaded], ignore_index=True)\n",
        "                st.success(f\"Loaded {len(df_uploaded)} rows from upload into session storage.\")\n",
        "                st.experimental_rerun()\n",
        "\n",
        "    elif page == \"Admin\":\n",
        "        st.subheader(\"Manager Analytics & Export\")\n",
        "        df = st.session_state.data.copy()\n",
        "        if df.empty:\n",
        "            st.info(\"No data to analyze. Start simulation or upload a file.\")\n",
        "        else:\n",
        "            df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "            st.markdown(\"**Summary statistics (latest data)**\")\n",
        "            st.write(df[[\"temp\",\"humidity\",\"vibration\"]].describe())\n",
        "\n",
        "            # simple anomaly rule: temp > setpoint + 10 or vibration > 1.5\n",
        "            df[\"anomaly_rule\"] = ((df[\"temp\"] > (st.session_state.setpoint_temp + 10)) | (df[\"vibration\"] > 1.5)).astype(int)\n",
        "            st.markdown(\"Anomaly counts by batch (rule-based)\")\n",
        "            anom_counts = df.groupby(\"batch_id\")[\"anomaly_rule\"].sum().reset_index().rename(columns={\"anomaly_rule\":\"anomaly_count\"})\n",
        "            st.table(anom_counts)\n",
        "\n",
        "            st.markdown(\"Download combined data (CSV)\")\n",
        "            csv = df.to_csv(index=False)\n",
        "            st.download_button(\"Download CSV\", data=csv, file_name=\"sensor_data_export.csv\", mime=\"text/csv\")\n",
        "\n",
        "    else:\n",
        "        st.subheader(\"Info\")\n",
        "        st.markdown(\"This demo app simulates a digital twin pipeline. Use the Upload page to test with real data. Use Control Panel to inject conditions and Dashboard to view live charts.\")\n",
        "\n",
        "    # footer: small help\n",
        "    st.markdown(\"---\")\n",
        "    st.caption(\"Demo app: operator credentials — user: operator / pass: op123. manager — user: manager / pass: mg123\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypwkG0kRtEcO",
        "outputId": "f66cb105-9330-4389-daa5-5e9e0617e0ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-18 09:53:24.263 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.264 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.265 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.267 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.268 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.269 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.274 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.276 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.277 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.279 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.280 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.281 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.282 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.283 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.285 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.286 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.287 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.288 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.289 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.290 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.291 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.292 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.293 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.294 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.295 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.295 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.296 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.297 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.298 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.299 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.300 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.300 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 09:53:24.301 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2Dj3QaGN-cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install streamlit pyngrok --quiet\n",
        "\n",
        "# Save your Streamlit app to a file\n",
        "app_code = \"\"\"\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "USERS = {\"operator\": {\"password\":\"op123\",\"role\":\"operator\"},\n",
        "         \"manager\": {\"password\":\"mg123\",\"role\":\"manager\"}}\n",
        "\n",
        "SIM_BATCH_SIZE = 20\n",
        "\n",
        "def authenticate(username, password):\n",
        "    user = USERS.get(username)\n",
        "    if user and user[\"password\"] == password:\n",
        "        return {\"username\": username, \"role\": user[\"role\"]}\n",
        "    return None\n",
        "\n",
        "if \"logged_in\" not in st.session_state:\n",
        "    st.session_state.logged_in = False\n",
        "    st.session_state.user = None\n",
        "    st.session_state.data = pd.DataFrame(columns=[\"timestamp\",\"temp\",\"humidity\",\"vibration\",\"batch_id\"])\n",
        "    st.session_state.running = False\n",
        "    st.session_state.sim_index = 0\n",
        "    st.session_state.setpoint_temp = 60.0\n",
        "    st.session_state.setpoint_humidity = 50.0\n",
        "    st.session_state.setpoint_vibration = 0.5\n",
        "\n",
        "def generate_record(i, setpoints):\n",
        "    temp = np.random.normal(setpoints[\"temp\"],2.0)+0.5*np.sin(i/10)\n",
        "    humidity = np.random.normal(setpoints[\"humidity\"],1.5)+0.2*np.cos(i/13)\n",
        "    vibration = max(0.01, np.random.normal(setpoints[\"vibration\"],0.05)+0.02*np.sin(i/7))\n",
        "    batch_id = f\"batch_{(i // SIM_BATCH_SIZE)+1}\"\n",
        "    return {\"timestamp\":pd.Timestamp.now(), \"temp\":round(float(temp),2),\n",
        "            \"humidity\":round(float(humidity),2), \"vibration\":round(float(vibration),3),\n",
        "            \"batch_id\":batch_id}\n",
        "\n",
        "def append_record(rec):\n",
        "    df = st.session_state.data\n",
        "    st.session_state.data = pd.concat([df,pd.DataFrame([rec])],ignore_index=True)\n",
        "\n",
        "# --- LOGIN ---\n",
        "if not st.session_state.logged_in:\n",
        "    st.title(\"🔐 Login\")\n",
        "    username = st.text_input(\"Username\")\n",
        "    password = st.text_input(\"Password\", type=\"password\")\n",
        "    if st.button(\"Login\"):\n",
        "        auth = authenticate(username, password)\n",
        "        if auth:\n",
        "            st.session_state.logged_in = True\n",
        "            st.session_state.user = auth\n",
        "            st.experimental_rerun()\n",
        "        else:\n",
        "            st.error(\"Invalid username or password. Try 'operator/op123' or 'manager/mg123'.\")\n",
        "else:\n",
        "    user = st.session_state.user\n",
        "    st.sidebar.title(f\"Welcome, {user['username']} ({user['role']})\")\n",
        "    if st.sidebar.button(\"Logout\"):\n",
        "        for k in list(st.session_state.keys()):\n",
        "            del st.session_state[k]\n",
        "        st.experimental_rerun()\n",
        "\n",
        "    st.markdown(\"## 🍪 Digital Twin Demo\")\n",
        "    left, right = st.columns([3,1])\n",
        "\n",
        "    # Simulation controls\n",
        "    with right:\n",
        "        if not st.session_state.running:\n",
        "            if st.button(\"Start Simulation\"):\n",
        "                st.session_state.running = True\n",
        "        else:\n",
        "            if st.button(\"Stop Simulation\"):\n",
        "                st.session_state.running = False\n",
        "        st.session_state.setpoint_temp = st.slider(\"Temp (°C)\",20.0,120.0,st.session_state.setpoint_temp)\n",
        "        st.session_state.setpoint_humidity = st.slider(\"Humidity (%)\",0.0,100.0,st.session_state.setpoint_humidity)\n",
        "        st.session_state.setpoint_vibration = st.slider(\"Vibration (g)\",0.0,5.0,st.session_state.setpoint_vibration)\n",
        "\n",
        "    # Dashboard\n",
        "    with left:\n",
        "        chart_placeholder = st.empty()\n",
        "        data_table = st.empty()\n",
        "        df = st.session_state.data.copy()\n",
        "\n",
        "        if st.session_state.running:\n",
        "            rec = generate_record(st.session_state.sim_index, {\n",
        "                \"temp\": st.session_state.setpoint_temp,\n",
        "                \"humidity\": st.session_state.setpoint_humidity,\n",
        "                \"vibration\": st.session_state.setpoint_vibration\n",
        "            })\n",
        "            append_record(rec)\n",
        "            st.session_state.sim_index += 1\n",
        "            time.sleep(0.25)\n",
        "\n",
        "        if df.empty:\n",
        "            st.info(\"No data yet. Start simulation.\")\n",
        "        else:\n",
        "            df = df.sort_values(\"timestamp\")\n",
        "            df2 = df.set_index(\"timestamp\")[[\"temp\",\"humidity\",\"vibration\"]].tail(300)\n",
        "            chart_placeholder.line_chart(df2)\n",
        "            data_table.dataframe(df.tail(10).reset_index(drop=True))\n",
        "\"\"\"\n",
        "\n",
        "with open(\"app.py\",\"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "# Run Streamlit app via ngrok\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "port = 8501\n",
        "public_url = ngrok.connect(port)\n",
        "print(f\"Streamlit public URL: {public_url}\")\n",
        "\n",
        "os.system(f\"streamlit run app.py --server.port {port} --server.headless true\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "K4Vix8IvRS-W",
        "outputId": "b178c857-84e1-44d3-a37b-8820ce3b5429"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-09-18T10:01:14+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-09-18T10:01:14+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-09-18T10:01:14+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4224177965.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8501\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Streamlit public URL: {public_url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Opening tunnel named: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    448\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: Usage of ngrok requires a verified account and authtoken.\\n\\nSign up for an account: https://dashboard.ngrok.com/signup\\nInstall your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_4018\\r\\n."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AxjlvwkfTgyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89f1b158",
        "outputId": "aef582d2-2acb-486c-a63e-5767a326a8cc"
      },
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
            "Try 'streamlit run --help' for help.\n",
            "\n",
            "Error: Invalid value: File does not exist: app.py\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0Kyour url is: https://pretty-jeans-train.loca.lt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\"\"\"\n",
        "Digital Twin Hackathon Demo App\n",
        "Features:\n",
        " - Simple login (operator / manager)\n",
        " - Live simulated sensor stream (start / stop)\n",
        " - Virtual control panel (setpoints affect simulated values)\n",
        " - Upload CSV / JSON to feed dashboard instead of simulation\n",
        " - Role-based UI: operator vs manager\n",
        " - Downloadable batch reports (manager)\n",
        "\"\"\"\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from io import StringIO\n",
        "\n",
        "# -------------------------\n",
        "# --------- CONFIG --------\n",
        "# -------------------------\n",
        "USERS = {\n",
        "    \"operator\": {\"password\": \"op123\", \"role\": \"operator\"},\n",
        "    \"manager\": {\"password\": \"mg123\", \"role\": \"manager\"}\n",
        "}\n",
        "\n",
        "SIM_BATCH_SIZE = 20  # number of records per batch (batch_id increments every SIM_BATCH_SIZE rows)\n",
        "\n",
        "# -------------------------\n",
        "# ---- Helper functions ---\n",
        "# -------------------------\n",
        "def authenticate(username: str, password: str):\n",
        "    user = USERS.get(username)\n",
        "    if user and user[\"password\"] == password:\n",
        "        return {\"username\": username, \"role\": user[\"role\"]}\n",
        "    return None\n",
        "\n",
        "def init_session():\n",
        "    if \"logged_in\" not in st.session_state:\n",
        "        st.session_state.logged_in = False\n",
        "        st.session_state.user = None\n",
        "    if \"data\" not in st.session_state:\n",
        "        st.session_state.data = pd.DataFrame(columns=[\"timestamp\",\"temp\",\"humidity\",\"vibration\",\"batch_id\"])\n",
        "    if \"running\" not in st.session_state:\n",
        "        st.session_state.running = False\n",
        "    if \"sim_index\" not in st.session_state:\n",
        "        st.session_state.sim_index = 0\n",
        "    if \"setpoint_temp\" not in st.session_state:\n",
        "        st.session_state.setpoint_temp = 60.0\n",
        "        st.session_state.setpoint_humidity = 50.0\n",
        "        st.session_state.setpoint_vibration = 0.5\n",
        "\n",
        "def generate_record(i, setpoints):\n",
        "    \"\"\"Simulate one sensor record influenced by setpoints.\"\"\"\n",
        "    base_temp = setpoints[\"temp\"]\n",
        "    base_hum = setpoints[\"humidity\"]\n",
        "    base_vib = setpoints[\"vibration\"]\n",
        "\n",
        "    # add small random fluctuations, and occasional drift\n",
        "    temp = np.random.normal(base_temp, 2.0) + 0.5 * np.sin(i/10)\n",
        "    humidity = np.random.normal(base_hum, 1.5) + 0.2 * np.cos(i/13)\n",
        "    vibration = max(0.01, np.random.normal(base_vib, 0.05) + 0.02 * np.sin(i/7))\n",
        "\n",
        "    batch_id = f\"batch_{(i // SIM_BATCH_SIZE) + 1}\"\n",
        "    return {\n",
        "        \"timestamp\": pd.Timestamp.now(),\n",
        "        \"temp\": round(float(temp), 2),\n",
        "        \"humidity\": round(float(humidity), 2),\n",
        "        \"vibration\": round(float(vibration), 3),\n",
        "        \"batch_id\": batch_id\n",
        "    }\n",
        "\n",
        "def append_record(rec):\n",
        "    df = st.session_state.data\n",
        "    df = pd.concat([df, pd.DataFrame([rec])], ignore_index=True)\n",
        "    st.session_state.data = df\n",
        "\n",
        "def load_uploaded_file(uploaded_file):\n",
        "    try:\n",
        "        file_ext = uploaded_file.name.split(\".\")[-1].lower()\n",
        "        if file_ext in (\"csv\", \"txt\"):\n",
        "            df = pd.read_csv(uploaded_file)\n",
        "        elif file_ext in (\"json\",):\n",
        "            df = pd.read_json(uploaded_file)\n",
        "        else:\n",
        "            st.error(\"Unsupported file type. Please upload CSV or JSON.\")\n",
        "            return None\n",
        "\n",
        "        # Expect at least columns: timestamp,temp,humidity,vibration,batch_id\n",
        "        # If timestamp missing, create one.\n",
        "        if \"timestamp\" not in df.columns:\n",
        "            df[\"timestamp\"] = pd.Timestamp.now()\n",
        "        required = [\"timestamp\",\"temp\",\"humidity\",\"vibration\"]\n",
        "        for c in required:\n",
        "            if c not in df.columns:\n",
        "                st.error(f\"Uploaded file missing required column: {c}\")\n",
        "                return None\n",
        "\n",
        "        # Normalize columns and types\n",
        "        df = df[[\"timestamp\",\"temp\",\"humidity\",\"vibration\"]].copy()\n",
        "        if \"batch_id\" in uploaded_file.name:  # optional way to specify batches via filename\n",
        "            df[\"batch_id\"] = uploaded_file.name.split(\".\")[0]\n",
        "        else:\n",
        "            # create batch ids if not present\n",
        "            df[\"batch_id\"] = [f\"batch_{(i // SIM_BATCH_SIZE) + 1}\" for i in range(len(df))]\n",
        "\n",
        "        # coerce timestamp\n",
        "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to parse uploaded file: {e}\")\n",
        "        return None\n",
        "\n",
        "# -------------------------\n",
        "# ------- UI LAYOUT -------\n",
        "# -------------------------\n",
        "st.set_page_config(page_title=\"Digital Twin Dashboard\", layout=\"wide\")\n",
        "init_session()\n",
        "\n",
        "if not st.session_state.logged_in:\n",
        "    st.title(\"🔐 Login\")\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        username = st.text_input(\"Username\")\n",
        "    with col2:\n",
        "        password = st.text_input(\"Password\", type=\"password\")\n",
        "\n",
        "    if st.button(\"Login\"):\n",
        "        auth = authenticate(username, password)\n",
        "        if auth:\n",
        "            st.session_state.logged_in = True\n",
        "            st.session_state.user = auth\n",
        "            st.experimental_rerun()\n",
        "        else:\n",
        "            st.error(\"Invalid username or password. Try 'operator/op123' or 'manager/mg123'.\")\n",
        "\n",
        "else:\n",
        "    user = st.session_state.user\n",
        "    st.sidebar.title(f\"Welcome, {user['username']} ({user['role']})\")\n",
        "    if st.sidebar.button(\"Logout\"):\n",
        "        # clear session and rerun\n",
        "        for k in list(st.session_state.keys()):\n",
        "            del st.session_state[k]\n",
        "        st.experimental_rerun()\n",
        "\n",
        "    # Navigation\n",
        "    page = st.sidebar.radio(\"Page\", [\"Dashboard\", \"Control Panel\", \"Upload Data\", \"Admin\" if user[\"role\"]==\"manager\" else \"Info\"])\n",
        "\n",
        "    # Top-level summary\n",
        "    st.markdown(\"## 🍪 Digital Twin — Food Process Demo\")\n",
        "    st.markdown(\"**Live mode:** Simulated data. You can upload real CSV/JSON to switch to offline mode.\")\n",
        "\n",
        "    # Right-side container for charts & table\n",
        "    if page == \"Dashboard\":\n",
        "        left, right = st.columns([3,1])\n",
        "\n",
        "        # Controls for simulation\n",
        "        with right:\n",
        "            st.subheader(\"Simulation Controls\")\n",
        "            if not st.session_state.running:\n",
        "                if st.button(\"Start Simulation\"):\n",
        "                    st.session_state.running = True\n",
        "            else:\n",
        "                if st.button(\"Stop Simulation\"):\n",
        "                    st.session_state.running = False\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "            st.write(\"Setpoints (affect simulation)\")\n",
        "            st.session_state.setpoint_temp = st.slider(\"Target Temp (°C)\", 20.0, 120.0, st.session_state.setpoint_temp)\n",
        "            st.session_state.setpoint_humidity = st.slider(\"Target Humidity (%)\", 0.0, 100.0, st.session_state.setpoint_humidity)\n",
        "            st.session_state.setpoint_vibration = st.slider(\"Target Vibration (g)\", 0.0, 5.0, st.session_state.setpoint_vibration)\n",
        "            st.markdown(\"---\")\n",
        "            st.write(\"Data source:\")\n",
        "            st.write(\"• If you've uploaded data, the app will display that. Otherwise the simulation runs.\")\n",
        "            if st.button(\"Clear Stored Data\"):\n",
        "                st.session_state.data = pd.DataFrame(columns=[\"timestamp\",\"temp\",\"humidity\",\"vibration\",\"batch_id\"])\n",
        "                st.success(\"Cleared stored data\")\n",
        "\n",
        "        # Main charts\n",
        "        with left:\n",
        "            st.subheader(\"Live Sensor Chart\")\n",
        "            chart_placeholder = st.empty()\n",
        "\n",
        "            st.subheader(\"Latest readings\")\n",
        "            data_table = st.empty()\n",
        "\n",
        "            # Insert uploaded data if present in session_state (upload page will fill it)\n",
        "            df = st.session_state.data.copy()\n",
        "\n",
        "            # If simulation running, generate a new record per rerun\n",
        "            if st.session_state.running:\n",
        "                # generate a single record per rerun (Streamlit reruns the script frequently)\n",
        "                rec = generate_record(st.session_state.sim_index, {\n",
        "                    \"temp\": st.session_state.setpoint_temp,\n",
        "                    \"humidity\": st.session_state.setpoint_humidity,\n",
        "                    \"vibration\": st.session_state.setpoint_vibration\n",
        "                })\n",
        "                append_record(rec)\n",
        "                st.session_state.sim_index += 1\n",
        "                # tiny pause so UI updates look natural (non-blocking enough)\n",
        "                time.sleep(0.25)\n",
        "\n",
        "            if df.empty:\n",
        "                st.info(\"No data yet. Start simulation or upload a file.\")\n",
        "            else:\n",
        "                # ensure timestamp is datetime and sorted\n",
        "                df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "                df = df.sort_values(\"timestamp\")\n",
        "                df2 = df.set_index(\"timestamp\")[[\"temp\",\"humidity\",\"vibration\"]].tail(300)\n",
        "\n",
        "                # show line chart\n",
        "                chart_placeholder.line_chart(df2)\n",
        "\n",
        "                # Latest table\n",
        "                data_table.dataframe(df.tail(10).reset_index(drop=True))\n",
        "\n",
        "            # Batch status: show last value per batch\n",
        "            st.subheader(\"Batch Status\")\n",
        "            if not df.empty:\n",
        "                last_per_batch = df.sort_values(\"timestamp\").groupby(\"batch_id\").tail(1)\n",
        "                st.table(last_per_batch[[\"batch_id\",\"temp\",\"humidity\",\"vibration\"]].reset_index(drop=True))\n",
        "\n",
        "    elif page == \"Control Panel\":\n",
        "        st.subheader(\"Virtual Control Panel\")\n",
        "        st.write(\"This panel simulates remote adjustments to the physical process. Changes affect subsequent simulated data.\")\n",
        "        st.markdown(\"- Adjust setpoints and then Start Simulation to observe the effect in the Dashboard.\")\n",
        "        st.write(\"Current setpoints:\")\n",
        "        st.write(f\"Temperature: {st.session_state.setpoint_temp} °C\")\n",
        "        st.write(f\"Humidity: {st.session_state.setpoint_humidity} %\")\n",
        "        st.write(f\"Vibration: {st.session_state.setpoint_vibration} g\")\n",
        "\n",
        "        if user[\"role\"] != \"operator\":\n",
        "            st.info(\"Control access is normally for operators. Managers can view and adjust for testing here.\")\n",
        "\n",
        "        # quick single-step controls (for demos)\n",
        "        if st.button(\"Simulate Heat Spike (+10°C) for 10 records\"):\n",
        "            base_t = st.session_state.setpoint_temp\n",
        "            for j in range(10):\n",
        "                rec = generate_record(st.session_state.sim_index + j, {\n",
        "                    \"temp\": base_t + 10,\n",
        "                    \"humidity\": st.session_state.setpoint_humidity,\n",
        "                    \"vibration\": st.session_state.setpoint_vibration\n",
        "                })\n",
        "                append_record(rec)\n",
        "            st.session_state.sim_index += 10\n",
        "            st.success(\"Injected heat spike (10 records)\")\n",
        "\n",
        "    elif page == \"Upload Data\":\n",
        "        st.subheader(\"Upload CSV or JSON sensor data\")\n",
        "        st.markdown(\"Expected columns: timestamp, temp, humidity, vibration (optional: batch_id). If timestamp absent, it will be added.\")\n",
        "        uploaded_file = st.file_uploader(\"Upload file\", type=[\"csv\",\"json\"])\n",
        "        if uploaded_file is not None:\n",
        "            df_uploaded = load_uploaded_file(uploaded_file)\n",
        "            if df_uploaded is not None:\n",
        "                st.session_state.data = pd.concat([st.session_state.data, df_uploaded], ignore_index=True)\n",
        "                st.success(f\"Loaded {len(df_uploaded)} rows from upload into session storage.\")\n",
        "                st.experimental_rerun()\n",
        "\n",
        "    elif page == \"Admin\":\n",
        "        st.subheader(\"Manager Analytics & Export\")\n",
        "        df = st.session_state.data.copy()\n",
        "        if df.empty:\n",
        "            st.info(\"No data to analyze. Start simulation or upload a file.\")\n",
        "        else:\n",
        "            df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
        "            st.markdown(\"**Summary statistics (latest data)**\")\n",
        "            st.write(df[[\"temp\",\"humidity\",\"vibration\"]].describe())\n",
        "\n",
        "            # simple anomaly rule: temp > setpoint + 10 or vibration > 1.5\n",
        "            df[\"anomaly_rule\"] = ((df[\"temp\"] > (st.session_state.setpoint_temp + 10)) | (df[\"vibration\"] > 1.5)).astype(int)\n",
        "            st.markdown(\"Anomaly counts by batch (rule-based)\")\n",
        "            anom_counts = df.groupby(\"batch_id\")[\"anomaly_rule\"].sum().reset_index().rename(columns={\"anomaly_rule\":\"anomaly_count\"})\n",
        "            st.table(anom_counts)\n",
        "\n",
        "            st.markdown(\"Download combined data (CSV)\")\n",
        "            csv = df.to_csv(index=False)\n",
        "            st.download_button(\"Download CSV\", data=csv, file_name=\"sensor_data_export.csv\", mime=\"text/csv\")\n",
        "\n",
        "    else:\n",
        "        st.subheader(\"Info\")\n",
        "        st.markdown(\"This demo app simulates a digital twin pipeline. Use the Upload page to test with real data. Use Control Panel to inject conditions and Dashboard to view live charts.\")\n",
        "\n",
        "    # footer: small help\n",
        "    st.markdown(\"---\")\n",
        "    st.caption(\"Demo app: operator credentials — user: operator / pass: op123. manager — user: manager / pass: mg123\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0RYv4-AvmNy",
        "outputId": "57ebb26d-e0eb-4673-e6ab-1771ec7e2f60"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-18 10:10:51.958 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.960 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.961 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.963 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.964 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.965 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.971 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.972 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.973 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.974 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.975 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.976 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.977 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.978 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.979 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.980 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.981 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.982 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.983 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.983 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.984 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.985 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.986 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.987 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.987 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.988 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.989 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.989 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.990 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.990 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.991 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-18 10:10:51.992 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "\n",
        "st.title(\"🚀 Hackathon Demo UI\")\n",
        "st.sidebar.success(\"Navigation Panel\")\n",
        "\n",
        "role = st.sidebar.selectbox(\"Login as:\", [\"Operator\", \"Manager\"])\n",
        "st.write(f\"Hello, you logged in as **{role}**\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD09GDIIU7Xx",
        "outputId": "f95087ee-1787-47b8-a0fc-f29050be7e63"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "\n",
        "# Kill previous tunnels if any\n",
        "ngrok.kill()\n",
        "\n",
        "# Set your ngrok authtoken here\n",
        "ngrok.set_auth_token(\"YOUR_NGROK_AUTH_TOKEN\")\n",
        "\n",
        "# Start Streamlit in background\n",
        "process = subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port\", \"8501\"])\n",
        "\n",
        "# Create public URL\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"🌍 Streamlit App URL:\", public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "lkwKbCILVEPu",
        "outputId": "ea036c1e-e494-437f-a31f-b83c23a468f3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-09-18T10:17:52+0000 lvl=eror msg=\"failed to reconnect session\" obj=tunnels.session err=\"authentication failed: The authtoken you specified does not look like a proper ngrok tunnel authtoken.\\nYour authtoken: YOUR_NGROK_AUTH_TOKEN\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-09-18T10:17:52+0000 lvl=eror msg=\"session closing\" obj=tunnels.session err=\"authentication failed: The authtoken you specified does not look like a proper ngrok tunnel authtoken.\\nYour authtoken: YOUR_NGROK_AUTH_TOKEN\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n\"\n",
            "ERROR:pyngrok.process.ngrok:t=2025-09-18T10:17:52+0000 lvl=eror msg=\"terminating with error\" obj=app err=\"authentication failed: The authtoken you specified does not look like a proper ngrok tunnel authtoken.\\nYour authtoken: YOUR_NGROK_AUTH_TOKEN\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n\"\n",
            "CRITICAL:pyngrok.process.ngrok:t=2025-09-18T10:17:52+0000 lvl=crit msg=\"command failed\" err=\"authentication failed: The authtoken you specified does not look like a proper ngrok tunnel authtoken.\\nYour authtoken: YOUR_NGROK_AUTH_TOKEN\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "PyngrokNgrokError",
          "evalue": "The ngrok process errored on start: authentication failed: The authtoken you specified does not look like a proper ngrok tunnel authtoken.\\nYour authtoken: YOUR_NGROK_AUTH_TOKEN\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2946968962.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Create public URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpublic_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngrok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8501\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🌍 Streamlit App URL:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(addr, proto, name, pyngrok_config, **options)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Opening tunnel named: {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     \u001b[0mapi_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ngrok_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Creating tunnel with options: {options}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/ngrok.py\u001b[0m in \u001b[0;36mget_ngrok_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0minstall_ngrok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36mget_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_current_processes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngrok_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_start_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyngrok_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyngrok/process.py\u001b[0m in \u001b[0;36m_start_process\u001b[0;34m(pyngrok_config)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartup_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             raise PyngrokNgrokError(f\"The ngrok process errored on start: {ngrok_process.startup_error}.\",\n\u001b[0m\u001b[1;32m    448\u001b[0m                                     \u001b[0mngrok_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                                     ngrok_process.startup_error)\n",
            "\u001b[0;31mPyngrokNgrokError\u001b[0m: The ngrok process errored on start: authentication failed: The authtoken you specified does not look like a proper ngrok tunnel authtoken.\\nYour authtoken: YOUR_NGROK_AUTH_TOKEN\\nInstructions to install your authtoken are on your ngrok dashboard:\\nhttps://dashboard.ngrok.com/get-started/your-authtoken\\r\\n\\r\\nERR_NGROK_105\\r\\n."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f037f92c",
        "outputId": "2145d4f2-8b6c-4441-8135-6087f924a198"
      },
      "source": [
        "!pip install streamlit"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.49.1-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.49.1-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.49.1\n"
          ]
        }
      ]
    }
  ]
}